{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUz3CTK3OZAbmCLAoLlwTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeyoung-b/Gwangju-AI/blob/master/1%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvLeJYuZGM-",
        "colab_type": "text"
      },
      "source": [
        "### 1. 언어\n",
        "* 구글번역(Google Translate): 텍스트 번역을 위해 구글이 무료로 제공하는 다언어 기계 번역 서비스이다. 안드로이드, iOS용 웹사이트 인터페이스, 모바일 앱, 그리고 개발자들이 브라우저 확장과 응용 소프트웨어를 개발하는 데 도움을 주는 API를 제공한다. 이 서비스는 2006년 4월 28일 처음 선보였다. 그 전까지 구글은 바벨피쉬, AOL, 야후 등의 번역 서비스에도 쓰였던 SYSTRAN 기반 번역기를 사용하였다.\n",
        "Babel Fish와 AOL, Yahoo!, MSN 등 내부적으로 SYSTRAN를 사용하는 번역 서비스와 달리 구글은 독자적인 번역 엔진을 사용하고 있다. 구글 번역 엔진, 기계 번역 중에서도 통계적 기계 번역이라는 기술을 이용하고 있다. 이 방법은 the United Nations Documents를 데이터로 닦아왔다. 번역된 데이터는 이백억 정도의 단어로 구성된다. 원래는 방법과 이를 목표 언어로 번역한 (유엔 번역사의 손에 의한 것)것을 사용하여 패턴을 찾아 그 때 번역에 필요한 전문가 시스템을 만드는 것이다. [참조](https://en.wikipedia.org/wiki/Google_Translate)  ![alt text](https://upload.wikimedia.org/wikipedia/commons/2/2b/Screenshot_of_Google_Translate.png)\n",
        "\n",
        "### 2. 음성\n",
        "* 알렉사(Alexa): 2014년 아마존에서 출시한 인공지능 플랫폼이다. 아마존 에코에 처음 사용되었다. 알렉사는 AccuWeather가 제공한 일기예보와 NPR, ESPN등 다양한 Tunein이 제공한 뉴스를 제공한다. 또한 알렉사 지원 장치들은 아마존 뮤직 계정에서 음악을 스트리밍한다. 알렉사는 경보, 타이머, 쇼핑 및 할 일 목록을 관리하고, 위키백과 문서에 액세스 할 수 있다. 알렉사는 사용자의 구글 캘린더에 있는 항목에 대한 질문에 응답할 수 있다. 홈 오토메이션 분야에서 알렉사는 Belkin Wemo, ecobee, Geeni, IFTTT, Insteon, LIFX, LightwaveRF, Nest Thermostats, Philips Hue, SmartThings, Wink, Yonomi의 장치와 상호 작용할 수 있다.\n",
        "알렉사를 이용해 음식을 주문할 수 있다. 알렉사는 클라우드 기반으로 작동되기 때문에, 알렉사를 자주 사용할 수록, 알렉사는 사용자가 말하는 패턴, 단어, 개인적인 기호등을 학습해서 더 잘 받아들인다. 현재 아마존은 알렉사에 대한 소프트웨어정보를 공개하였고, 이러한 정보들을 이용해 여러 기업에서 가전제품, 자동차 등에 도입했다.  [참조](https://en.wikipedia.org/wiki/Amazon_Alexa)  \n",
        "\n",
        "     ![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ7041tA5u7V_tCyExtV9oCAKI7gv9czBj8gQBBvIjNxcjRc6gI&usqp=CAU)\n",
        "\n",
        "### 3. 이미지\n",
        "* Face ID: iphone과 ipad pro에서 사용되는 얼굴인식 시스템으로 기기의 잠금을 유저의 얼굴을 인식하여 해제한다. 그 외에도 기기 내에서 결제나 다른 프로그램에 로그인 할 때에도 사용된다. 한 개의 센서와 세 개의 모듈(도트 프로젝터, 적외선 카메라, 투광 일루미네이터)로 구성된 트루뎁스 카메라 시스템이 사용된다. 보이지 않는 3만 개 이상의 도트를 얼굴에 투사해 사용자의 얼굴 맵을 만들고 적외선 카메라가 얼굴의 도트 패턴을 판독하고 데이터 일치 여부를 확인해 사용자를 인증한다. 애플 측에 따르면 사진이나 가면을 이용한 스푸핑을 통해 보안이 뚫리지 않으며, 적외선 센서를 통해 어두운 곳에서도 작동한다. 또 새로운 침셋인 'A11 바이오닉'은 머신러닝을 통해 외보 변화를 인지한다. 안경과 모자를 써도, 수염을 기르고 머리 모양을 바꿔도 사용자를 알아보며 선글라스를 착용한 상태에섣도 작동한다. 자는 동안 얼굴을 인증하면 보안이 쉽게 뚫리지 않을까 하는 우려도 있지만, 페이스아이디는 눈을 똑바로 뜨고 기기를 응시할 때만 잠금을 해제한다. 이 기술은 보안 외에도 애니모티콘에도 활용된다. 애니모티콘은 기존의 정적인 이모티콘에서 벗어나 사용자 표정을 반영해 움직이는 이모티콘이다. 트루뎁스 카메라가 50개 이상의 근육 움직임을 분석해 고양이, 로봇, 외계인 등 12종의 애니모티콘에 투영한다. 이는 증강현실 분야와 맞닿아 있다. 현실에 가상의 이미지를 반영하는 AR은 정교하게 현실을 인식하고 어색하지 않게 가상 이미지를 녹여내는 게 관건이다. 트루뎁스 카메라 시스템은 이런 측면에서 AR 분야에 정교함을 더해줄 것으로 기대된다.  [참조1](https://en.wikipedia.org/wiki/Face_ID) / [참조2](https://terms.naver.com/entry.nhn?docId=4352595&cid=59088&categoryId=59096) \n",
        "![alt text](https://img.etimg.com/thumb/msid-68499437,width-1200,height-900,imgsize-467252,overlay-etpanache/photo.jpg)\n",
        "\n",
        "### 4. 자율주행\n",
        "* 자율주행 자동차(Self-driving Car): 주변 환경을 인지하고 운전자의 아주 적은 개입으로 또는 개입이 없이 스스로 움직이는 자동차를 말한다. 주위를 인지하기 위해 radar, lidar, sonar, GPS, odometry, inertial measurement units 등의 센서들이 필요하다. 0부터 5까지 총 6단계의 레벨로 나누며, 5단계의 자율주행 자동차는 탑승자의 어떠한 도움없이 모든 주행과 주차를 스스로 할 수 있다. 현재 많은 자동차 기업뿐만 아니라 구글, NVIDIA 같은 IT 기업들이 개발 중인데, 그중 가장 앞서있다고 평가되는 구글의 자율주행차는 약 600~1000여대의 차량으로 실제 도로 주행을 하여 주행거리가 1,300만km를 넘어섰다. 이에 반해 테슬라의 경우, 2020년 1월 자율주행 시스템으로 실도로 총주행거리는 30억km가 넘으며, 70여만대의 자율주행 하드웨어 차량을 통해서 단, 하루에도 약 881만km의 데이터를 수집할 수 있어서, 데이터의 양이 얼마나 큰 지가 압도적인 차이를 만들어 내는 딥러닝 기반의 자율 주행 개발에 있어서 가장 유리한 위치를 차지하고 있다.  [참조](https://en.wikipedia.org/wiki/Self-driving_car)\n",
        "![alt text](https://www.autonomousvehicleinternational.com/wp-content/uploads/2019/05/1.1-For-CapGemini-story.gif)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}